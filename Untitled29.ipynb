{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "understanding\n",
        "DataFrames and Series, the two primary data structures in Pandas."
      ],
      "metadata": {
        "id": "N2byNJwL6ZcZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRpArqET5M5K",
        "outputId": "2c979336-2ad2-4833-e6bd-dfec23b9d810"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    1\n",
            "1    2\n",
            "2    3\n",
            "3    4\n",
            "4    5\n",
            "dtype: int64\n",
            "       Name  Age\n",
            "0   Thanmai   61\n",
            "1  vyshnavi   66\n",
            "2    anitha   64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "# Series\n",
        "series=pd.Series([1, 2, 3, 4, 5])\n",
        "print(series)\n",
        "# DataFrame\n",
        "data=[['Thanmai',61],['vyshnavi',66],['anitha',64]]\n",
        "df=pd.DataFrame(data, columns=['Name','Age'])\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using dictonaries"
      ],
      "metadata": {
        "id": "-xPlNWiN6z2k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Series from a dictionary\n",
        "series=pd.Series({'a': 1, 'b': 2, 'c': 3})\n",
        "print(series)\n",
        "# DataFrame from a dictionary\n",
        "data={'Name': ['Alice', 'Bob', 'Charlie'], 'Age': [24, 27, 22]}\n",
        "df=pd.DataFrame(data)\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWMvqyTX6XBt",
        "outputId": "10746574-c8de-40c7-a41a-6eb72ca2ea83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a    1\n",
            "b    2\n",
            "c    3\n",
            "dtype: int64\n",
            "      Name  Age\n",
            "0    Alice   24\n",
            "1      Bob   27\n",
            "2  Charlie   22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using csv"
      ],
      "metadata": {
        "id": "X3DhIAWR7lru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('data5.csv')\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaQy7gIp6zIu",
        "outputId": "fcbfc47a-49b9-4136-cb0d-89b99e5084f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           Date  Year Month  Recession  Consumer_Confidence  \\\n",
            "0     1/31/1980  1980   Jan          1               108.24   \n",
            "1     2/29/1980  1980   Feb          1                98.75   \n",
            "2     3/31/1980  1980   Mar          1               107.48   \n",
            "3     4/30/1980  1980   Apr          1               115.01   \n",
            "4     5/31/1980  1980   May          1                98.72   \n",
            "..          ...   ...   ...        ...                  ...   \n",
            "523   8/31/2023  2023   Aug          0               103.36   \n",
            "524   9/30/2023  2023   Sep          0               101.55   \n",
            "525  10/31/2023  2023   Oct          0               124.66   \n",
            "526  11/30/2023  2023   Nov          0                97.09   \n",
            "527  12/31/2023  2023   Dec          0                95.92   \n",
            "\n",
            "     Seasonality_Weight      Price  Advertising_Expenditure  Competition  \\\n",
            "0                  0.50  27483.571                     1558            7   \n",
            "1                  0.75  24308.678                     3048            4   \n",
            "2                  0.20  28238.443                     3137            3   \n",
            "3                  1.00  32615.149                     1653            7   \n",
            "4                  0.20  23829.233                     1319            4   \n",
            "..                  ...        ...                      ...          ...   \n",
            "523                0.25  27852.993                     1793            6   \n",
            "524                0.07  21183.704                     1028            5   \n",
            "525                0.12  15975.589                     1148            9   \n",
            "526                0.25  16862.288                     4850            5   \n",
            "527                0.34  25240.425                     2319            3   \n",
            "\n",
            "        GDP  Growth_Rate  unemployment_rate  Automobile_Sales  \\\n",
            "0    60.223     0.010000                5.4             456.0   \n",
            "1    45.986    -0.309594                4.8             555.9   \n",
            "2    35.141    -0.308614                3.4             620.0   \n",
            "3    45.673     0.230596                4.2             702.8   \n",
            "4    52.997     0.138197                5.3             770.4   \n",
            "..      ...          ...                ...               ...   \n",
            "523  57.169     0.764155                2.6            1579.6   \n",
            "524  59.315     0.036180                2.5            1123.4   \n",
            "525  19.472    -2.046169                2.5            1685.9   \n",
            "526  27.904     0.302179                2.9            2124.6   \n",
            "527  13.518    -1.064211                2.1            3538.5   \n",
            "\n",
            "        Vehicle_Type        City  \n",
            "0      Supperminicar     Georgia  \n",
            "1      Supperminicar    New York  \n",
            "2    Mediumfamilycar    New York  \n",
            "3      Supperminicar    Illinois  \n",
            "4    Smallfamiliycar  California  \n",
            "..               ...         ...  \n",
            "523     Executivecar    New York  \n",
            "524  Smallfamiliycar  California  \n",
            "525           Sports  California  \n",
            "526  Smallfamiliycar     Georgia  \n",
            "527  Smallfamiliycar     Georgia  \n",
            "\n",
            "[528 rows x 15 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "operations such as selecting data, filtering rows"
      ],
      "metadata": {
        "id": "KR9HXckW_D1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data={'Name': ['Alice', 'Bob', 'Charlie'], 'Age': [24, 27, 22]}\n",
        "df=pd.DataFrame(data)\n",
        "# Selecting a column\n",
        "print(df['Name'])\n",
        "# Selecting multiple columns\n",
        "print(df[['Name', 'Age']])\n",
        "# Selecting rows by index\n",
        "print(df.iloc[0])\n",
        "print(df.iloc[-1])\n",
        "# Filtering rows\n",
        "filter=df[df['Age'] > 25]\n",
        "print(filter)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyjW7Krc7n87",
        "outputId": "28fe088f-2f92-4ce1-c84d-d8b86fd8e542"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0      Alice\n",
            "1        Bob\n",
            "2    Charlie\n",
            "Name: Name, dtype: object\n",
            "      Name  Age\n",
            "0    Alice   24\n",
            "1      Bob   27\n",
            "2  Charlie   22\n",
            "Name    Alice\n",
            "Age        24\n",
            "Name: 0, dtype: object\n",
            "Name    Charlie\n",
            "Age          22\n",
            "Name: 2, dtype: object\n",
            "  Name  Age\n",
            "1  Bob   27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Handling missing data"
      ],
      "metadata": {
        "id": "iIMjsKHpCATK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('Titanic-Dataset - Titanic-Dataset.csv')\n",
        "\n",
        "# Handling missing data\n",
        "print(\"DataFrame before handling missing values:\")\n",
        "print(df)\n",
        "print(\"\\n\")\n",
        "\n",
        "df.fillna(0, inplace=True)\n",
        "print(\"DataFrame after filling missing values with 0:\")\n",
        "print(df)\n",
        "print(\"\\n\")\n",
        "\n",
        "df.drop_duplicates(inplace=True)\n",
        "print(\"DataFrame after removing duplicates:\")\n",
        "print(df)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Data type conversions\n",
        "print(\"DataFrame before data type conversion:\")\n",
        "print(df.dtypes)\n",
        "print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3yQYnG4_FOO",
        "outputId": "2b50c353-e451-4d85-e315-9cf78ad6082e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame before handling missing values:\n",
            "     PassengerId  Survived  Pclass  \\\n",
            "0              1         0       3   \n",
            "1              2         1       1   \n",
            "2              3         1       3   \n",
            "3              4         1       1   \n",
            "4              5         0       3   \n",
            "..           ...       ...     ...   \n",
            "886          887         0       2   \n",
            "887          888         1       1   \n",
            "888          889         0       3   \n",
            "889          890         1       1   \n",
            "890          891         0       3   \n",
            "\n",
            "                                                  Name     Sex   Age  SibSp  \\\n",
            "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                             Allen, Mr. William Henry    male  35.0      0   \n",
            "..                                                 ...     ...   ...    ...   \n",
            "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
            "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
            "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
            "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
            "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
            "\n",
            "     Parch            Ticket     Fare Cabin Embarked  \n",
            "0        0         A/5 21171   7.2500   NaN        S  \n",
            "1        0          PC 17599  71.2833   C85        C  \n",
            "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3        0            113803  53.1000  C123        S  \n",
            "4        0            373450   8.0500   NaN        S  \n",
            "..     ...               ...      ...   ...      ...  \n",
            "886      0            211536  13.0000   NaN        S  \n",
            "887      0            112053  30.0000   B42        S  \n",
            "888      2        W./C. 6607  23.4500   NaN        S  \n",
            "889      0            111369  30.0000  C148        C  \n",
            "890      0            370376   7.7500   NaN        Q  \n",
            "\n",
            "[891 rows x 12 columns]\n",
            "\n",
            "\n",
            "DataFrame after filling missing values with 0:\n",
            "     PassengerId  Survived  Pclass  \\\n",
            "0              1         0       3   \n",
            "1              2         1       1   \n",
            "2              3         1       3   \n",
            "3              4         1       1   \n",
            "4              5         0       3   \n",
            "..           ...       ...     ...   \n",
            "886          887         0       2   \n",
            "887          888         1       1   \n",
            "888          889         0       3   \n",
            "889          890         1       1   \n",
            "890          891         0       3   \n",
            "\n",
            "                                                  Name     Sex   Age  SibSp  \\\n",
            "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                             Allen, Mr. William Henry    male  35.0      0   \n",
            "..                                                 ...     ...   ...    ...   \n",
            "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
            "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
            "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   0.0      1   \n",
            "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
            "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
            "\n",
            "     Parch            Ticket     Fare Cabin Embarked  \n",
            "0        0         A/5 21171   7.2500     0        S  \n",
            "1        0          PC 17599  71.2833   C85        C  \n",
            "2        0  STON/O2. 3101282   7.9250     0        S  \n",
            "3        0            113803  53.1000  C123        S  \n",
            "4        0            373450   8.0500     0        S  \n",
            "..     ...               ...      ...   ...      ...  \n",
            "886      0            211536  13.0000     0        S  \n",
            "887      0            112053  30.0000   B42        S  \n",
            "888      2        W./C. 6607  23.4500     0        S  \n",
            "889      0            111369  30.0000  C148        C  \n",
            "890      0            370376   7.7500     0        Q  \n",
            "\n",
            "[891 rows x 12 columns]\n",
            "\n",
            "\n",
            "DataFrame after removing duplicates:\n",
            "     PassengerId  Survived  Pclass  \\\n",
            "0              1         0       3   \n",
            "1              2         1       1   \n",
            "2              3         1       3   \n",
            "3              4         1       1   \n",
            "4              5         0       3   \n",
            "..           ...       ...     ...   \n",
            "886          887         0       2   \n",
            "887          888         1       1   \n",
            "888          889         0       3   \n",
            "889          890         1       1   \n",
            "890          891         0       3   \n",
            "\n",
            "                                                  Name     Sex   Age  SibSp  \\\n",
            "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                             Allen, Mr. William Henry    male  35.0      0   \n",
            "..                                                 ...     ...   ...    ...   \n",
            "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
            "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
            "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   0.0      1   \n",
            "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
            "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
            "\n",
            "     Parch            Ticket     Fare Cabin Embarked  \n",
            "0        0         A/5 21171   7.2500     0        S  \n",
            "1        0          PC 17599  71.2833   C85        C  \n",
            "2        0  STON/O2. 3101282   7.9250     0        S  \n",
            "3        0            113803  53.1000  C123        S  \n",
            "4        0            373450   8.0500     0        S  \n",
            "..     ...               ...      ...   ...      ...  \n",
            "886      0            211536  13.0000     0        S  \n",
            "887      0            112053  30.0000   B42        S  \n",
            "888      2        W./C. 6607  23.4500     0        S  \n",
            "889      0            111369  30.0000  C148        C  \n",
            "890      0            370376   7.7500     0        Q  \n",
            "\n",
            "[891 rows x 12 columns]\n",
            "\n",
            "\n",
            "DataFrame before data type conversion:\n",
            "PassengerId      int64\n",
            "Survived         int64\n",
            "Pclass           int64\n",
            "Name            object\n",
            "Sex             object\n",
            "Age            float64\n",
            "SibSp            int64\n",
            "Parch            int64\n",
            "Ticket          object\n",
            "Fare           float64\n",
            "Cabin           object\n",
            "Embarked        object\n",
            "dtype: object\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysis"
      ],
      "metadata": {
        "id": "t7uTewWjDSly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Summary statistics of the Titanic dataset:\")\n",
        "print(df.describe(include='all'))\n",
        "print(\"\\n\")\n",
        "\n",
        "# Grouping by\n",
        "grouped_by_sex=df.groupby('Sex')[['Age', 'Fare']].mean()\n",
        "\n",
        "print(\"Mean Age and Fare by Sex:\")\n",
        "print(grouped_by_sex)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Grouping by\n",
        "survival_rate=df.groupby(['Pclass', 'Sex'])['Survived'].mean()\n",
        "\n",
        "print(\"Survival Rate by Passenger Class and Sex:\")\n",
        "print(survival_rate)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Creating a new DataFrame with additional data\n",
        "additional_data = pd.DataFrame({\n",
        "    'PassengerId': [1, 2, 3, 4, 5],\n",
        "    'CabinClass': ['First', 'Second', 'Third', 'First', 'Third']\n",
        "})\n",
        "\n",
        "# Merging\n",
        "merged_df=pd.merge(df, additional_data, left_on='PassengerId', right_on='PassengerId', how='left')\n",
        "print(\"Merged DataFrame (with additional data):\")\n",
        "print(merged_df.head())\n",
        "print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKnP2dBdCD57",
        "outputId": "c218e8ce-ec58-44b0-bad4-9bddaeb9dbab"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary statistics of the Titanic dataset:\n",
            "        PassengerId    Survived      Pclass                     Name   Sex  \\\n",
            "count    891.000000  891.000000  891.000000                      891   891   \n",
            "unique          NaN         NaN         NaN                      891     2   \n",
            "top             NaN         NaN         NaN  Braund, Mr. Owen Harris  male   \n",
            "freq            NaN         NaN         NaN                        1   577   \n",
            "mean     446.000000    0.383838    2.308642                      NaN   NaN   \n",
            "std      257.353842    0.486592    0.836071                      NaN   NaN   \n",
            "min        1.000000    0.000000    1.000000                      NaN   NaN   \n",
            "25%      223.500000    0.000000    2.000000                      NaN   NaN   \n",
            "50%      446.000000    0.000000    3.000000                      NaN   NaN   \n",
            "75%      668.500000    1.000000    3.000000                      NaN   NaN   \n",
            "max      891.000000    1.000000    3.000000                      NaN   NaN   \n",
            "\n",
            "               Age       SibSp       Parch  Ticket        Fare  Cabin Embarked  \n",
            "count   891.000000  891.000000  891.000000     891  891.000000  891.0      891  \n",
            "unique         NaN         NaN         NaN     681         NaN  148.0        4  \n",
            "top            NaN         NaN         NaN  347082         NaN    0.0        S  \n",
            "freq           NaN         NaN         NaN       7         NaN  687.0      644  \n",
            "mean     23.799293    0.523008    0.381594     NaN   32.204208    NaN      NaN  \n",
            "std      17.596074    1.102743    0.806057     NaN   49.693429    NaN      NaN  \n",
            "min       0.000000    0.000000    0.000000     NaN    0.000000    NaN      NaN  \n",
            "25%       6.000000    0.000000    0.000000     NaN    7.910400    NaN      NaN  \n",
            "50%      24.000000    0.000000    0.000000     NaN   14.454200    NaN      NaN  \n",
            "75%      35.000000    1.000000    0.000000     NaN   31.000000    NaN      NaN  \n",
            "max      80.000000    8.000000    6.000000     NaN  512.329200    NaN      NaN  \n",
            "\n",
            "\n",
            "Mean Age and Fare by Sex:\n",
            "              Age       Fare\n",
            "Sex                         \n",
            "female  23.203822  44.479818\n",
            "male    24.123345  25.523893\n",
            "\n",
            "\n",
            "Survival Rate by Passenger Class and Sex:\n",
            "Pclass  Sex   \n",
            "1       female    0.968085\n",
            "        male      0.368852\n",
            "2       female    0.921053\n",
            "        male      0.157407\n",
            "3       female    0.500000\n",
            "        male      0.135447\n",
            "Name: Survived, dtype: float64\n",
            "\n",
            "\n",
            "Merged DataFrame (with additional data):\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked CabinClass  \n",
            "0      0         A/5 21171   7.2500     0        S      First  \n",
            "1      0          PC 17599  71.2833   C85        C     Second  \n",
            "2      0  STON/O2. 3101282   7.9250     0        S      Third  \n",
            "3      0            113803  53.1000  C123        S      First  \n",
            "4      0            373450   8.0500     0        S      Third  \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Advantages of Using Pandas\n",
        "Data Structure Flexibility:\n",
        "\n",
        "DataFrames: Pandas' primary data structure, the DataFrame, is a 2-dimensional, size-mutable, and potentially heterogeneous tabular data structure. It is more powerful and versatile than traditional Python data structures like lists, dictionaries, and even NumPy arrays. DataFrames allow for the manipulation of large datasets with complex operations, such as filtering, grouping, and aggregating data, all with a simple and consistent API.\n",
        "Series: Pandas Series is like a column in a table, and it can hold any data type. It allows for easy indexing and alignment, which is very useful in time-series analysis.\n",
        "Efficiency:\n",
        "\n",
        "Pandas is optimized for performance with large datasets, allowing for quick data processing and manipulation. Operations on large datasets, such as sorting, merging, and filtering, are significantly faster with Pandas than with native Python loops or list comprehensions.\n",
        "Data Handling Capabilities:\n",
        "\n",
        "Pandas provides robust methods for handling missing data, a common issue in real-world datasets. Functions like fillna(), dropna(), and interpolate() allow for easy imputation or removal of missing values.\n",
        "Pandas also supports powerful operations like merging, joining, and concatenating DataFrames, making it easier to combine and reshape datasets from multiple sources."
      ],
      "metadata": {
        "id": "IgR1g8mWD7tx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Real-World Examples Where Pandas is Essential\n",
        "Data Cleaning:\n",
        "\n",
        "In any data science project, cleaning and preprocessing data is often the most time-consuming step. Pandas simplifies this process by providing functions for handling missing data, filtering outliers, normalizing data, and more. For instance, in the Titanic dataset, Pandas made it easy to fill in missing ages with the median age or to filter out records where data was insufficient.\n",
        "Exploratory Data Analysis (EDA):\n",
        "\n",
        "EDA is critical to understanding the underlying patterns in data before applying machine learning models. Pandas allows for quick aggregation of data, visualization of distributions, and calculation of correlation coefficients, which are essential steps in EDA. For example, grouping passengers by class and calculating the survival rate in the Titanic dataset gave immediate insights into how class affected survival outcomes.\n",
        "\n",
        "Financial Data Analysis:\n",
        "\n",
        "For professionals in finance, Pandas is indispensable for analyzing stock prices, calculating moving averages, or performing backtesting of trading strategies. Its ability to handle time-series data and integrate with financial data sources makes it a preferred tool."
      ],
      "metadata": {
        "id": "IhnvDRtEEBqH"
      }
    }
  ]
}